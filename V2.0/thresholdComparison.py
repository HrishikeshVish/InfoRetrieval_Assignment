import json
from search import search
from pageRanking import rankByFreq, rankByTFIDF
import pandas as pd

import os
from tqdm import tqdm
import matplotlib.pyplot as plt

corpus_path = './TelevisionNews'
corpus_files_list = os.listdir(corpus_path)
totalSize = 0
fileNames = {}
# create a dictionary of URL vs filenames. Dict[URL] points to the file where URL exists
for file_name in tqdm(corpus_files_list):
    try:
        partial_corpus = pd.read_csv('./TelevisionNews/' + file_name)
        if 'URL' in partial_corpus.columns:
            for i in partial_corpus["URL"]:
                fileNames[i] = file_name
                
    except:
        pd.errors.EmptyDataError

        
with open('groundTruth2.json', encoding='utf-8') as f:
    # Load elastic search results
    data = json.load(f)
URLs = {}
queries = list(data.keys())
snippets = {}

counter = 0
for ele in queries:
    #extract all the queries
    actualValues = []
    retVal = data[ele]["result"]
    snippets[ele] = []
    elasticFiles = []
    URLs[ele] = []
    for i in retVal:
        #Extract URLs generated by the elastic search for each query
        URLs[ele].append(i["_source"]["ï»¿URL"])
        elasticFiles.append(i["_source"]["ï»¿URL"])
        
    #Run the same query against my model    
    similarity_scores = {}
    document_list = search(ele)
    ranked_order_of_docs = rankByFreq(document_list)
    if(len(ranked_order_of_docs)>2500):
        ranked_docs = rankByTFIDF(ranked_order_of_docs[0:2500], 5, ele)
    else:
        ranked_docs = rankByTFIDF(ranked_order_of_docs, 5, ele)
    actULs = []
    for doc in ranked_docs:
        f,o = doc[2].split(" ")
        similarity = doc[1]
        #similarity_scores[f] = similarity
        corpus = pd.read_csv('./TelevisionNews/'+f)
        url = corpus['URL'][int(o)]
        similarity_scores[url] = similarity
        actULs.append(url)
        
        #Create a dictionary of filename vs similarity 
    for ele in elasticFiles:
        # Compare similarity value of my model with results of elastic search
        if ele in similarity_scores.keys():
            if(similarity_scores[ele] > 0.5):
                actualValues.append(url)
                print(similarity_scores[ele])
        else:
            print(0)
    remVals = len(actualValues) - len(URLs)
    j = 0
    tempcount = 0
    while(j<remVals):
        if(actULs[tempcount] not in actualValues):
            actualValues.append(actULs[tempcount])
            j+=1
            tempcount+=1
        else:
            tempcount+=1
    with open('./actual/'+str(counter)+'.json', "w") as f:
        json.dump(actualValues, f)
        
        
    counter+=1
        
        
        
    

